最新spark tar 包下载下来，安装好jdk ，scala。
spark-env.sh
```
export JAVA_HOME=/opt/client/jdk
export SCALA_HOME=/usr/local/scala-2.11.8
#export SPARK_MASTER_IP=172.18.18.103
#export SPARK_MASTER_PORT=7077
#export SPARK_MASTER_WEBUI_PORT=8080
export SPARK_LOCAL_DIR=/opt/ldl/BigDataComponent/service/spark/data/tmp
#export SPARK_WORKER_MEMORY=4g
export SPARK_EXECUTOR_MEMORY=2g
export SPARK_DRIVER_MEMORY=1g
#export SPARK_WORKER_CORES=4
export SPARK_CLASSPATH=$SPARK_CLASSPATH:/opt/client/Spark/spark/jars/mysql-connector-java-5.1.44-bin.jar
```

启动spark-shell
```
scala> val df = spark.read.json("/opt/ldl/BigDataComponent/service/spark/examples/src/main/resources/people.json")
df: org.apache.spark.sql.DataFrame = [age: bigint, name: string]

scala> df.show
+----+-------+
| age|   name|
+----+-------+
|null|Michael|
|  30|   Andy|
|  19| Justin|
+----+-------+


scala> df.printSchema
root
 |-- age: long (nullable = true)
 |-- name: string (nullable = true)


scala> df.filter(df("age") > 21).show
+---+----+
|age|name|
+---+----+
| 30|Andy|
+---+----+


scala> df.groupBy("age").count.show
+----+-----+
| age|count|
+----+-----+
|  19|    1|
|null|    1|
|  30|    1|
+----+-----+
scala> 
```
