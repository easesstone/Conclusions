## 常见随机失败

| 常见Suite 失败名称|单元测试|错误栈|所处工程  |  出现次数 |
|  :----: | :----: | :----: | :----: | :----: | 
|    org.apache.spark.deploy.master.PersistenceEngineSuite  |  ZooKeeperPersistenceEngine  | null    | Spark_UT_Test_24 |  1 |
|   org.apache.spark.streaming.kafka.DirectKafkaStreamSuite |     null    | null  |  null |  0 |
|   org.apache.spark.streaming.ReceiverSuite  |    receiver life cycle  |  Error Message  |  Spark_UT_Test_09 | 1 |
|    org.apache.spark.network.RequestTimeoutIntegrationSuite | furtherRequestsDelay | null | Spark_UT_Test_88 | 1 |

###  暴力解决办法，（不可行。）
```
因为随机失败也就那几个常见的UT 随机失败，
所以只要工程是失败的，就认为是随机失败引起的，则重跑随机失败的Suite。
6+1 中工程的解决办法。
在run-test 的脚本中，判断跑test 脚本的退出状态码，如果非0，则重跑上述两个test.例如
if [ $? -ne 0 ];then 
	build/sbt  $SBT_MAVEN_PROFILES_ARGS  "test-only org.apache.spark.deploy.master.PersistenceEngineSuite"  
	| grep -v Resolving
fi

不可行的原因：
因为如果这个工程的失败，如果不是随机失败引起的，那么，如果也当做随机失败处理。这个根本点的逻辑就不正确。
```

### 更优雅的方式
```
解决方法描述。
1，工程目录下面有一份要跑的Suite 的白名单，有可能失败的时候，有一些Suite 没有跑，
   则找出已经跑了的Suite, 和白名单的Suite对比，把没有跑的Suite 也跑一遍.
   I,找出所有的Suite ： find .  \( -name *test*.xml  -o -name  *org*.xml \)  | grep test-reports  | awk -F / '{print $NF}' | sed 's/.xml//g' > ranSuites
   II ，与白名单对比，找出还没有跑的Suite.
 2，如果UT 跑失败，则，错误栈信息里面都会有ForkError 字样，如此，通过这个办法，找出跑错误的Suite，重跑这个Suite。
   思路，利用第一步找出的已经跑了的ranSuites 文件。
   形如下面，只要含有
   find .  \( -name *test*.xml  -o -name  *org*.xml \)  | grep test-reports  >> ranSuites.xml
   for suitexml in `cat ranSuites.xml`;do message=`cat $suitexml | grep "failure message"`;if [ "x$message" != "x" ];then  echo ${suitexml} | awk -F / '{print $NF}' | sed 's/.xml//g' | tee -a errorSuites ; fi ; done 
   参考：
   i=0;for suitexml in `cat ranSuites.xml`;do message=`cat $suitexml | grep "failure message"`;if [ "x$message" != "x" ];then let i++;echo "${i}-----${suitexml}";echo ${suitexml} | awk -F / '{print $NF}' | sed 's/.xml//g' | tee -a suites_final ; fi ; done 
   cat ./streaming/target/test-reports/org.apache.spark.streaming.BasicOperationsSuite.xml |grep "failure message"
   
```
