# 基于对象存储的项目架构
## 需求
解决大小图和json文件的存储问题
## 方案1
### 方案描述
保持原有架构不变，Ftp把图片存到本地（作为一个生产者，临时存储，临时缓存或者临时缓冲），
Ceph 从本地读取图片，存到自己的集群中，删除ftp 中的缓冲（作为一个消费者，作为最终的存储终端）。

### 需要解决的问题
1，什么时候清理缓存。  
2，如何对外提供数据读取服务。  
（备注：解决了这两个问题，然后具体的实施流程就问题不大了）
#### 1，什么时候清理缓存
~~直接进行读取各个ftp中的数据：  
读取ftp 前一天的，或者之前某几天的数据，由Ceph 进行读取，  
待存储到Ceph 之后，然后进行删除（需要验证可行性，FTP 需要分目录）~~  

~~ftp的目录结构大概如下（如此需要清理ftpdata 目录下，某个目录下面的内容即可）：    
ftpdata/3K01E84PAU00498/2017/12/15/15/2017_12_15_15_56_49_6318_1.jpg
ftpdata/3K01E84PAU00498/2017/12/15/15/2017_12_15_15_56_49_6318_0.jpg
ftpdata/3K01E84PAU00498/2017/12/15/15/2017_12_15_15_56_49_6318_0.json~~

可行的实现过程：（参考方案2，从ES 中查询，然后把数据删除掉）  
1,从ES 中查询到前一天的数据，并且没有被同步过的数据。把其从ftp 中读取，并且存到ceph 中  
2，存储的同时，生成url，更新ftpurl 这个字段的值为ceph 中的值。  
3，删除ftp 上的数据。  


#### 2，如何对外提供数据读取服务
对外提供的URL的时候(同理也可以参考方案2中的内容)  
1,动态库的以图搜图，平外组获取图片的时候，还是需要通过dobbo 接口调用来进行获取。
需要知道图片名字即可。（然后到Es中获取URl）

2,动态库的历史抓拍，URI 可以直接从es 中获取，通过Dubbo 来进行调用，
key 是文件名====》获取URI


~~以下方案Pass（之前想到的是）  
1，先确认ftp 中是否有数据，如果有，则直接返回FTP 的URL  
2，如果没有，则到CEPH 集群中根据图片名字生成URL  
（需要验证可行性，FTP 数据该如何确认数据是否是真的存在  
数据的返回利用dubbo 接口实现（封装如上1,2 两个流程），
像静态细信息库一样（解决spark sql 以图搜图数据的返回））。~~

#### 备注
1， 并发访问Es 中的数据，是否会出现问题。


~~问题1的时候，涉及多个应用程序操作同一个资源的情况，也就是并发问题。  
（例如图片的URL 已经返回给平台，某张图片显示的是ftp的URL，
但是刚好在这个时候ceph 集群中存好了数据，
把ftp 的这张图片给删掉了。虽然几率可能很小，但是不排除这个可能性，通过dubbo 调用几率可以更小，
并且数据迁移到Ceph 可以放到后半夜进行。）~~


## 方案2
### 方案描述
同样的保持原有的ftp以及项目的整个结构不变，添加一个Ceph 存储集群，把ftp 作为一个
缓冲处理。另外起一个线程或者程序，把ftp 中的图片迁移到ceph 集群中。

采用如下方法：  
1，ftp 把接收到的图片的ftp URL 发送到Kafka。  
2，起一个streaming 程序或者kafka 客户端的api 程序，把ftp 中的数据保存到ceph 中。
（需要保存偏移量）

### 同方案1需要解决的问题
1，什么时候清理缓存。  
2，如何对外提供数据读取服务。
 
 #### 1，什么时候清理缓存（ftp 中的图片）。
 整个存储流程描述为如下：  
 
 1，生成队列：  
 ftp 把存到本地的图片等的数据的URL以<文件名，文件ftp地址>的形式发送到Kafka 
 集群中的一个Topic A。  
 
 2，存储数据：  
 起一个本地的SparkStreaming 程序，或者集群模式的SparkStreming 程序，或者直接
 调用Kafka 客户端的Java Api,读取Kafka 集群中Topic A 中的内容，然后获取数据存储到CEPH 中。  
 
~~同时在存储的时候，需要生成对外访问URL 发送到Kafka 中。  
（发送到kafka 中的URL ，如何同步到Parquest 文件中???????）  
（这个步骤不现实，就算发送了，也无法同步到Parquest中，所以此不走Pass 掉 ）~~
 
 ~~（在把ftp 中的数据往ceph 集群复制的同时，把从Kafka 中读取到的数据，同步到ES 中，保存的时候，
 除了URL 外，还需要保存时间，时间根据URL 进行截取来存储。方便后面根据时间搜索来把ftp 中的缓存数据清除掉）  
   这个步骤可以不用操作，因为KafkaToParquet这个程序已经动态库的信息同步到es 中了。~~
 
 这个时候还没有删除ftp 缓冲的数据，抓拍图片的显示还是从ftp 中读取，
  不影响特征的提取和抓拍图的实时显示。  
  
   
 3，删除数据：  
 另起一个定时任务到ES中查询前一天，或者前两天的数据，然后到ftp 中把数据删除掉，
 同时，把其中数据的ftpurl 字段的值，换成ceph 的url。
 


#### 2，如何对外提供数据读取服务。
1,动态库的以图搜图，平外组获取图片的时候，还是需要通过dobbo 接口调用来进行获取。
需要知道图片名字即可。（然后到Es中获取URl）

2,动态库的历史抓拍，URI 可以直接从es 中获取。
 
 

##  方案1和方案2 优缺点对比。
### 共同优点：
都是把ftp 作为本地缓存，不应现实时抓拍图的显示和特征值的提取。    
都是本着组件分离和解耦的思想，尽可能的不对其他组件有太多的依赖。  
功能单一，只考虑的是存储的事情。


### 共同缺点：
方案1:
~~A，涉及多个应用程序操作同一个资源的情况，也就是并发问题。  
（例如图片的URL 已经返回给平台，某张图片显示的是ftp的URL，
但是刚好在这个时候ceph 集群中存好了数据，
把ftp 的这张图片给删掉了。虽然几率可能很小，但是不排除这个可能性，通过dubbo 调用几率可以更小，
并且数据迁移到Ceph 可以放到后半夜进行。）~~

方案2
缺点：
也有并发访问ES 中数据的问题，即并发操作统一资源的问题。

总结起来，就是，都有极小概率的并发访问问题。  
### 其他
动态库以图搜图都是需要从dubbo 中调用获取到。

### 方案1 分析

缺点：

~~1，删除的时候，遍历比较麻烦，需要一个一个ftp 服务器进行遍历。（方案2，改善了这个缺点）
（删除的时候并没有麻烦，也可以像方案2一样从ES 中查询，然后再删除数据）  
不是缺点~~

优点：
I，不用增加Kakka 队列这个组件。
II，实现起来，相对于方案2简单，无读取kafka 这个操作，不依赖于kafka 中的内容

### 方案2分析 
优点：
A，Kafka 中的队列，提取特征这个过程也可以利用，这样就可以避免ftp 挂掉的时候，内存中滞后的数据
丢失掉的问题。  

## 方案3
从ES 中查询（利用ES 来实现？？？？？？）

## Bug 假设和分析（和解决办法）
假如删除过程中ftp 挂掉了？？
（ES 动态信息库中，增加一个字段标志，标志此数据是否已经同步到ceph 中了。）


## 流程
需求  ========》 概要和方案（可行性分析） =====(评审)======》详细设计 =====（串讲）=======》 代码编写
 =================》线下简单测试================》 线上测试  ========》Bug 修复=======》需求闭环