# CEPH 基础知识
## 文件存储，块存储，对象存储
### 文件存储
```
常见的比如Linux 文件系统ETX4，Windows 的文件系统FAT32/NTFS
优点：
1，便宜。
2，方便实现数据共享。（利用FTP，NFS服务架构）
缺点：
1，读写效率慢。
```
### 块存储
```
对服务器上的一块或者多块物理硬盘，映射成服务器上的一个大的盘，
然后通过划分逻辑分区，做raid，或者LVM 等方式划分成逻辑硬盘。
总的来说，通过一系列的技术，把一个或者多个物理盘组合成一个，然后划分成多个逻辑硬盘。
优点：
1，数据保护技术：RAID，LVM（数据备份技术）。
2，可以组合多个硬盘，合成一个大的硬盘，对外提供一个更大的容量。
3，逻辑盘的容量，比如1个G，容量可能是多个物理硬盘中的一小部分，
比如第一个硬盘中取100M，第二个硬盘中取100M等等……，这样可以在读写的时候提升效率，
因为可以并行操作多个盘。
4，采用SAN（Storage Area Network，存储区域网络）架构，提高传输速率和读写效率。
缺点：
1，造价贵，成本高。
2，不利于数据共享，主机和主机之间，不同操作系统之间。

```
### 对象存储
```
格式化后的硬盘（文件系统），通过对象存储软件，实现数据的存储。
综合了块存储和文件系统存储的优点：读写传输速度，易于实现文件共享。
```
## CEPH 简介
CEPH 可以作为文件存储系统，块存储和对象存储系统。
CEPH 存储集群，需要设置的是每一个CEPH节点，网络，和存储集群。  
至少需要一个CEPH Monitor，CEPH Manage， 和CEPH OSD （Object Server Device）。  
![CEPH](http://docs.ceph.com/docs/master/_images/ditaa-409784e9076840f895f8cbd328a523961cda0d87.png)
(注：其中的MDSs 是元数据服务，只有CEPH 当文件系统的时候进行使用。)  
### Monitors:   
1，维护集群状态的映射，包括的是监视器映射，管理器映射，OSD映射，CRUSH映射。这些映射是集群间守护进程相互协作的关键。  
2，负责管理守护进程和客户端间的认证。  
一般至少需要三台进行冗余而保证集群的高可用性。  
  
### Manages：  
守护进程，跟踪运行时的指标和CEPH集群状态，包括存储利用率，性能指标和系统负载情况。    
CEPH daemons 里加载着python 插件，对外提供集群信息，给dashboard 使用，以及提供restful的api.  
为了高可用，请至少起两个Monitor。


### OSDs：（对象存储Daemons）
1，存储数据，处理数据的备份，恢复，和均衡。  
2，监听其他OSDs 的状态，提供监控信息给Monitors 和Managers。  
为了进群的冗余和高可用OSDs 节点至少需要三个节点。

### MDSs (元数据服务)，只有使用文件系统的时候使用。
```

```

### Conclusion
```
CEPH 的数据，不管是块储存，文件存储，还是对象存储，最终以对象的形式存储在逻辑存储池中。  
使用CRUSH算法，计算那个对象组放置哪个对象，并且进一步计算那个CEPH OSD 进程存放哪个组。  
CRUSH 算法有利于集群动态扩展，重新平衡和恢复。  
```

